{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be sourced from [Brisbane City Council Library Checkouts](https://www.data.brisbane.qld.gov.au/data/dataset/library-checkouts-branch-date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the SparkSession and SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up the session\n",
    "2. Set up the context\n",
    "3. Raise the log level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T, Window\n",
    "\n",
    "spark = (SparkSession\n",
    "            .builder\n",
    "            .appName(\"Demo\")\n",
    "            .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read in the csv\n",
    "2. Print the record count\n",
    "3. Print the schema\n",
    "4. Print 3 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = spark.read.csv(\"library_checkouts_202206.csv\", header=True, quote=\"\\\"\", escape=\"\\\"\").drop(\"status\", \"language\")\n",
    "\n",
    "print(f\"Number of records: {df_in.count()}\\n\")\n",
    "\n",
    "df_in.printSchema()\n",
    "\n",
    "df_in.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read in a mapping for library_code -> library_name\n",
    "2. Cast the date column to timestamp\n",
    "3. Apply the library_code mapping\n",
    "4. Check the date column was correctly remapped\n",
    "4. Print 3 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_map = spark.read.csv(\"library_mapping.csv\", header=True)\n",
    "\n",
    "df = (df_in.withColumn(\"date\", F.to_timestamp(F.col(\"date\"), \"yyyyMMddHHmmss\"))\n",
    "        .withColumnRenamed(\"checkout_library\", \"library_code\")\n",
    "        .join(library_map, \"library_code\", \"left\"))\n",
    "\n",
    "print(df.schema[\"date\"], \"\\n\")\n",
    "\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Print the number of libraries\n",
    "2. Print the top 3 libraries by number of checkouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_count = (df.select(\"library_name\")\n",
    "                   .distinct()\n",
    "                   .count())\n",
    "\n",
    "print(f\"Distinct libraries: {library_count}\\n\")\n",
    "\n",
    "print(\"Top 3 libraries by number of checkouts\")\n",
    "\n",
    "(df.groupBy(\"library_name\")\n",
    "   .count()\n",
    "   .orderBy(\"count\", ascending=False)\n",
    "   .show(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which titles are the most popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Print the top 10 titles by number of checkouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy(\"title\", \"item_type_code\")\n",
    "   .count()\n",
    "   .orderBy(\"count\", ascending=False)\n",
    "   .show(10, truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the most popular title in each item type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the checkout count by title and category\n",
    "2. Rank the titles within each category type\n",
    "3. Select the top ranked title (in each category)\n",
    "4. Print the top 10 top ranked titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy(\"title\", \"item_type_code\")\n",
    "   .count()\n",
    "   .withColumn(\"rank\", F.rank().over(Window.partitionBy(\"item_type_code\").orderBy(F.desc(\"count\"))))\n",
    "   .filter(F.col(\"rank\") == 1)\n",
    "   .drop(\"rank\")\n",
    "   .orderBy(\"count\", ascending=False)\n",
    "   .show(10, truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the borrowing pattern look like for a specific library?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Print 20 consecutive checkouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = df.select(\"library_code\", \"library_name\", \"title\", \"author\", \"item_type_code\", \"age\", \"date\")\n",
    "\n",
    "(df_exp.orderBy(\"library_code\", \"date\").drop(\"title\")\n",
    "    .show(truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can we group sets of checkouts together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_records_into_checkouts(df, allowed_gap_in_seconds, show_intermediate=True):\n",
    "    # Add a row number to act as a tie break when ordering identical dates\n",
    "    df_checkout = df.withColumn(\"row_number\", F.row_number().over(Window.partitionBy(\"library_code\").orderBy(\"date\")))\n",
    "\n",
    "    # Grab the time of the immediately previous checkout\n",
    "    df_checkout = df_checkout.withColumn(\"previous_checkout\", F.lag(F.col(\"date\")).over(Window.partitionBy(\"library_code\").orderBy(\"date\", \"row_number\")))\n",
    "\n",
    "    # Only consider it to be the same checkout if the previous occurred within the previous X seconds\n",
    "    df_checkout = (df_checkout.withColumn(\"time_between_checkouts\", F.unix_timestamp(\"date\") - F.unix_timestamp(\"previous_checkout\"))\n",
    "                    .withColumn(\"is_same_checkout\", F.col(\"time_between_checkouts\") <= allowed_gap_in_seconds)\n",
    "                    .withColumn(\"new_checkout_increment\", F.when(F.col(\"is_same_checkout\"), 0).otherwise(1))\n",
    "                    .drop(\"is_same_checkout\"))\n",
    "\n",
    "    # The checkout IDs can be generated by doing a cumulative sum \n",
    "    df_checkout = df_checkout.withColumn(\"checkout_id\", F.sum(\"new_checkout_increment\")\n",
    "                                            .over(Window.partitionBy(\"library_code\").orderBy(\"date\", \"row_number\").rangeBetween(Window.unboundedPreceding, 0)))\n",
    "\n",
    "    if show_intermediate:\n",
    "        df_checkout.drop(\"title\", \"author\", \"item_type_code\", \"age\").orderBy(\"library_code\", \"date\", \"row_number\").show(5)\n",
    "\n",
    "    return df_checkout.drop(\"row_number\", \"previous_checkout\", \"new_checkout_increment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Group the records into clusters with unique checkout_ids\n",
    "2. Print statistics about the checkout_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkout = group_records_into_checkouts(df_exp, 5)\n",
    "\n",
    "(df_checkout.groupBy(\"library_code\", \"checkout_id\")\n",
    "                       .count()\n",
    "                       .select(\"count\")\n",
    "                       .describe()\n",
    "                       .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate some checkout cluster statistics (count, duration)\n",
    "2. Get the checkout cluster with the largest number of checkouts\n",
    "3. Print the cluster stats\n",
    "3. Print all of the records in that cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_record = (df_checkout.groupBy(\"library_code\", \"checkout_id\")\n",
    "                         .agg(F.count(\"library_code\").alias(\"count\"), \n",
    "                              F.max(\"date\").alias(\"max_date\"),\n",
    "                              F.min(\"date\").alias(\"min_date\"))\n",
    "                         .withColumn(\"duration\", F.unix_timestamp(F.col(\"max_date\")) - F.unix_timestamp(F.col(\"min_date\")))\n",
    "                         .orderBy(\"count\", ascending=False)\n",
    "                         .limit(1))\n",
    "\n",
    "top_record.show()\n",
    "\n",
    "biggest_checkout = df_checkout.join(top_record, [\"library_code\", \"checkout_id\"])\n",
    "\n",
    "(biggest_checkout.drop(\"library_code\", \"library_name\", \"count\", \"min_date\", \"max_date\", \"duration\")\n",
    "                 .orderBy(\"date\")\n",
    "                 .show(100, truncate=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.count())\n",
    "print(df.count())\n",
    "print(df.count())\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cache()\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"test\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"test\", F.max(F.col(\"library_name\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
